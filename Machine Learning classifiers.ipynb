{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Handling Imbalanced Dataset With Machine Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "from itable import PrettyTable, TableStyle,CellStyle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> GAIT Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>STS</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.4</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BMI   STS  y\n",
       "0  33.4  15.3  0\n",
       "1  29.4  11.1  0\n",
       "2  24.5  12.3  0\n",
       "3  20.9  11.0  0\n",
       "4  31.9  11.6  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('gait1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data size\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.792793\n",
       "1    0.207207\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imbalanced target\n",
    "df.y.value_counts() / len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77, 2), (34, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(labels=['y'], axis=1),  # drop the y\n",
    "    df['y'],  # just the y\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression on Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_class= LogisticRegression()\n",
    "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv=KFold(n_splits=5,random_state=None,shuffle=False)\n",
    "clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.43      0.50      0.46        34\n",
      "weighted avg       0.73      0.85      0.79        34\n",
      "\n",
      "0.8529411764705882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,clf.predict(X_test)))\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print(accuracy_score(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random Forest on orig. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  2]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.42      0.47      0.44        34\n",
      "weighted avg       0.72      0.79      0.76        34\n",
      "\n",
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rf.predict(X_test)))\n",
    "print(classification_report(y_test, rf.predict(X_test)))\n",
    "print(accuracy_score(y_test,rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Ada Boost on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  5]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        29\n",
      "           1       0.17      0.20      0.18         5\n",
      "\n",
      "    accuracy                           0.74        34\n",
      "   macro avg       0.51      0.51      0.51        34\n",
      "weighted avg       0.76      0.74      0.75        34\n",
      "\n",
      "0.7352941176470589\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,ada.predict(X_test)))\n",
    "print(classification_report(y_test, ada.predict(X_test)))\n",
    "print(accuracy_score(y_test,ada.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SVM on Orig. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.43      0.50      0.46        34\n",
      "weighted avg       0.73      0.85      0.79        34\n",
      "\n",
      "0.8529411764705882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,sv.predict(X_test)))\n",
    "print(classification_report(y_test, sv.predict(X_test)))\n",
    "print(accuracy_score(y_test,sv.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Decision Tree on Orig. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  5]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        29\n",
      "           1       0.17      0.20      0.18         5\n",
      "\n",
      "    accuracy                           0.74        34\n",
      "   macro avg       0.51      0.51      0.51        34\n",
      "weighted avg       0.76      0.74      0.75        34\n",
      "\n",
      "0.7352941176470589\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,dt.predict(X_test)))\n",
    "print(classification_report(y_test, dt.predict(X_test)))\n",
    "print(accuracy_score(y_test,dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes on orign. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  1]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92        29\n",
      "           1       0.50      0.20      0.29         5\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.69      0.58      0.60        34\n",
      "weighted avg       0.82      0.85      0.83        34\n",
      "\n",
      "0.8529411764705882\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,nb.predict(X_test)))\n",
    "print(classification_report(y_test, nb.predict(X_test)))\n",
    "print(accuracy_score(y_test,nb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KNN on Orig. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "kn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  1]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.42      0.48      0.45        34\n",
      "weighted avg       0.72      0.82      0.77        34\n",
      "\n",
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,kn.predict(X_test)))\n",
    "print(classification_report(y_test, kn.predict(X_test)))\n",
    "print(accuracy_score(y_test,kn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Applying SMOTE on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(\n",
    "    sampling_strategy='auto',  # samples only the minority class\n",
    "    random_state=0,  # for reproducibility\n",
    "    k_neighbors=5,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118, 2), (118,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape, y_resampled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    59\n",
       " 1    18\n",
       " Name: y, dtype: int64,\n",
       " 1    59\n",
       " 0    59\n",
       " Name: y, dtype: int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(), y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic Regrission on SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_class= LogisticRegression()\n",
    "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv=KFold(n_splits=5,random_state=None,shuffle=False)\n",
    "clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1)\n",
    "clf.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  8]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.62        34\n",
      "   macro avg       0.40      0.36      0.38        34\n",
      "weighted avg       0.69      0.62      0.65        34\n",
      "\n",
      "0.6176470588235294\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,clf.predict(X_test)))\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print(accuracy_score(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random Forest On SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  5]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        29\n",
      "           1       0.17      0.20      0.18         5\n",
      "\n",
      "    accuracy                           0.74        34\n",
      "   macro avg       0.51      0.51      0.51        34\n",
      "weighted avg       0.76      0.74      0.75        34\n",
      "\n",
      "0.7352941176470589\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rf.predict(X_test)))\n",
    "print(classification_report(y_test, rf.predict(X_test)))\n",
    "print(accuracy_score(y_test,rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Ada Boost on SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  4]\n",
      " [ 3  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88        29\n",
      "           1       0.33      0.40      0.36         5\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.61      0.63      0.62        34\n",
      "weighted avg       0.81      0.79      0.80        34\n",
      "\n",
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,ada.predict(X_test)))\n",
    "print(classification_report(y_test, ada.predict(X_test)))\n",
    "print(accuracy_score(y_test,ada.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SVM on SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16 13]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.55      0.65        29\n",
      "           1       0.07      0.20      0.11         5\n",
      "\n",
      "    accuracy                           0.50        34\n",
      "   macro avg       0.44      0.38      0.38        34\n",
      "weighted avg       0.69      0.50      0.57        34\n",
      "\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,sv.predict(X_test)))\n",
    "print(classification_report(y_test, sv.predict(X_test)))\n",
    "print(accuracy_score(y_test,sv.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Tree on SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  7]\n",
      " [ 3  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.81        29\n",
      "           1       0.22      0.40      0.29         5\n",
      "\n",
      "    accuracy                           0.71        34\n",
      "   macro avg       0.55      0.58      0.55        34\n",
      "weighted avg       0.78      0.71      0.74        34\n",
      "\n",
      "0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,dt.predict(X_test)))\n",
    "print(classification_report(y_test, dt.predict(X_test)))\n",
    "print(accuracy_score(y_test,dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes on SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  7]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80        29\n",
      "           1       0.12      0.20      0.15         5\n",
      "\n",
      "    accuracy                           0.68        34\n",
      "   macro avg       0.49      0.48      0.48        34\n",
      "weighted avg       0.74      0.68      0.70        34\n",
      "\n",
      "0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,nb.predict(X_test)))\n",
    "print(classification_report(y_test, nb.predict(X_test)))\n",
    "print(accuracy_score(y_test,nb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KNN on SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "kn.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  9]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75        29\n",
      "           1       0.10      0.20      0.13         5\n",
      "\n",
      "    accuracy                           0.62        34\n",
      "   macro avg       0.47      0.44      0.44        34\n",
      "weighted avg       0.73      0.62      0.66        34\n",
      "\n",
      "0.6176470588235294\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,kn.predict(X_test)))\n",
    "print(classification_report(y_test, kn.predict(X_test)))\n",
    "print(accuracy_score(y_test,kn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Applying SMOTE with Edited Nearest Neighbour(SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need ENN  as argument of SMOTEENN\n",
    "enn = EditedNearestNeighbours(\n",
    "    sampling_strategy='auto',\n",
    "    n_neighbors=3,\n",
    "    kind_sel='all',\n",
    "    n_jobs=4)\n",
    "\n",
    "\n",
    "smenn = SMOTEENN(\n",
    "    sampling_strategy='auto',  # samples only the minority class\n",
    "    random_state=0,  # for reproducibility\n",
    "    smote=sm,\n",
    "    enn=enn,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "X_smenn, y_smenn = smenn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118, 2), (84, 2))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of oversampled datasets\n",
    "\n",
    "X_resampled.shape, X_smenn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    59\n",
       " 1    18\n",
       " Name: y, dtype: int64,\n",
       " 1    59\n",
       " 0    59\n",
       " Name: y, dtype: int64,\n",
       " 0    59\n",
       " 1    25\n",
       " Name: y, dtype: int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of minority class observations\n",
    "\n",
    "y_train.value_counts(), y_resampled.value_counts(), y_smenn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3>Logistic with SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_class= LogisticRegression()\n",
    "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv=KFold(n_splits=5,random_state=None,shuffle=False)\n",
    "clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1)\n",
    "clf.fit(X_smenn, y_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  1]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.42      0.48      0.45        34\n",
      "weighted avg       0.72      0.82      0.77        34\n",
      "\n",
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,clf.predict(X_test)))\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print(accuracy_score(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest With SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_smenn, y_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  2]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.42      0.47      0.44        34\n",
      "weighted avg       0.72      0.79      0.76        34\n",
      "\n",
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rf.predict(X_test)))\n",
    "print(classification_report(y_test, rf.predict(X_test)))\n",
    "print(accuracy_score(y_test,rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ada Boost With SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_smenn, y_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  3]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.76        34\n",
      "   macro avg       0.42      0.45      0.43        34\n",
      "weighted avg       0.72      0.76      0.74        34\n",
      "\n",
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,ada.predict(X_test)))\n",
    "print(classification_report(y_test, ada.predict(X_test)))\n",
    "print(accuracy_score(y_test,ada.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SVM with SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(X_smenn, y_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  2]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.42      0.47      0.44        34\n",
      "weighted avg       0.72      0.79      0.76        34\n",
      "\n",
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,sv.predict(X_test)))\n",
    "print(classification_report(y_test, sv.predict(X_test)))\n",
    "print(accuracy_score(y_test,sv.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Tree with SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_smenn, y_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  2]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.42      0.47      0.44        34\n",
      "weighted avg       0.72      0.79      0.76        34\n",
      "\n",
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,dt.predict(X_test)))\n",
    "print(classification_report(y_test, dt.predict(X_test)))\n",
    "print(accuracy_score(y_test,dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes with SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_smenn, y_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  2]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.42      0.47      0.44        34\n",
      "weighted avg       0.72      0.79      0.76        34\n",
      "\n",
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,nb.predict(X_test)))\n",
    "print(classification_report(y_test, nb.predict(X_test)))\n",
    "print(accuracy_score(y_test,nb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KNN With SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "kn.fit(X_smenn, y_smenn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  3]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.76        34\n",
      "   macro avg       0.42      0.45      0.43        34\n",
      "weighted avg       0.72      0.76      0.74        34\n",
      "\n",
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,kn.predict(X_test)))\n",
    "print(classification_report(y_test, kn.predict(X_test)))\n",
    "print(accuracy_score(y_test,kn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Applying SMOTE With Tomek (SMOTETomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need tomek as argument of SMOTETomek\n",
    "tl = TomekLinks(\n",
    "    sampling_strategy='all',\n",
    "    n_jobs=4)\n",
    "\n",
    "smtomek = SMOTETomek(\n",
    "    sampling_strategy='auto',  # samples only the minority class\n",
    "    random_state=0,  # for reproducibility\n",
    "    smote=sm,\n",
    "    tomek=tl,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "X_smtl, y_smtl = smtomek.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118, 2), (98, 2))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of oversampled datasets\n",
    "\n",
    "X_resampled.shape, X_smtl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    59\n",
       " 1    18\n",
       " Name: y, dtype: int64,\n",
       " 1    59\n",
       " 0    59\n",
       " Name: y, dtype: int64,\n",
       " 1    49\n",
       " 0    49\n",
       " Name: y, dtype: int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of minority class observations\n",
    "\n",
    "y_train.value_counts(), y_resampled.value_counts(),y_smtl.value_counts()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic With SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_class= LogisticRegression()\n",
    "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv=KFold(n_splits=5,random_state=None,shuffle=False)\n",
    "clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1)\n",
    "clf.fit(X_smtl, y_smtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  8]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76        29\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.62        34\n",
      "   macro avg       0.40      0.36      0.38        34\n",
      "weighted avg       0.69      0.62      0.65        34\n",
      "\n",
      "0.6176470588235294\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,clf.predict(X_test)))\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print(accuracy_score(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest With SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_smtl, y_smtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  7]\n",
      " [ 3  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.81        29\n",
      "           1       0.22      0.40      0.29         5\n",
      "\n",
      "    accuracy                           0.71        34\n",
      "   macro avg       0.55      0.58      0.55        34\n",
      "weighted avg       0.78      0.71      0.74        34\n",
      "\n",
      "0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rf.predict(X_test)))\n",
    "print(classification_report(y_test, rf.predict(X_test)))\n",
    "print(accuracy_score(y_test,rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>AdaBoost With SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_smtl, y_smtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  5]\n",
      " [ 3  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        29\n",
      "           1       0.29      0.40      0.33         5\n",
      "\n",
      "    accuracy                           0.76        34\n",
      "   macro avg       0.59      0.61      0.60        34\n",
      "weighted avg       0.80      0.76      0.78        34\n",
      "\n",
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,ada.predict(X_test)))\n",
    "print(classification_report(y_test, ada.predict(X_test)))\n",
    "print(accuracy_score(y_test,ada.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SVM With SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(X_smtl, y_smtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15 14]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.52      0.62        29\n",
      "           1       0.07      0.20      0.10         5\n",
      "\n",
      "    accuracy                           0.47        34\n",
      "   macro avg       0.43      0.36      0.36        34\n",
      "weighted avg       0.68      0.47      0.55        34\n",
      "\n",
      "0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,sv.predict(X_test)))\n",
    "print(classification_report(y_test, sv.predict(X_test)))\n",
    "print(accuracy_score(y_test,sv.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Tree With SMOTETomek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_smtl, y_smtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  6]\n",
      " [ 3  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.84        29\n",
      "           1       0.25      0.40      0.31         5\n",
      "\n",
      "    accuracy                           0.74        34\n",
      "   macro avg       0.57      0.60      0.57        34\n",
      "weighted avg       0.79      0.74      0.76        34\n",
      "\n",
      "0.7352941176470589\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,dt.predict(X_test)))\n",
    "print(classification_report(y_test, dt.predict(X_test)))\n",
    "print(accuracy_score(y_test,dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes With SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_smtl, y_smtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  7]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80        29\n",
      "           1       0.12      0.20      0.15         5\n",
      "\n",
      "    accuracy                           0.68        34\n",
      "   macro avg       0.49      0.48      0.48        34\n",
      "weighted avg       0.74      0.68      0.70        34\n",
      "\n",
      "0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,nb.predict(X_test)))\n",
    "print(classification_report(y_test, nb.predict(X_test)))\n",
    "print(accuracy_score(y_test,nb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KNN With SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "kn.fit(X_smtl, y_smtl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 10]\n",
      " [ 4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73        29\n",
      "           1       0.09      0.20      0.13         5\n",
      "\n",
      "    accuracy                           0.59        34\n",
      "   macro avg       0.46      0.43      0.43        34\n",
      "weighted avg       0.72      0.59      0.64        34\n",
      "\n",
      "0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,kn.predict(X_test)))\n",
    "print(classification_report(y_test, kn.predict(X_test)))\n",
    "print(accuracy_score(y_test,kn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
